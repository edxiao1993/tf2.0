{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train/255.0, x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.24002191, -0.03332424, -0.3269905 , -0.23978993,  0.55071354,\n",
       "        -0.1371544 , -0.17721656,  0.2061882 , -0.50335157,  0.34438357]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12182916, 0.09269121, 0.06910364, 0.07540005, 0.16621986,\n",
       "        0.08354985, 0.08026882, 0.11777618, 0.05793063, 0.1352306 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4823117"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=loss_fn,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2888 - accuracy: 0.9162\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.1392 - accuracy: 0.9591\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1047 - accuracy: 0.9683\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0847 - accuracy: 0.9737\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.0735 - accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fde89c71d10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 0s - loss: 0.0360 - accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06976577922534198, 0.9785]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "    model, tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=30015, shape=(5, 10), dtype=float32, numpy=\n",
       "array([[1.39998690e-07, 1.09598425e-07, 2.43071754e-05, 6.74947281e-04,\n",
       "        2.68982978e-11, 4.74061608e-06, 1.20726400e-12, 9.99287546e-01,\n",
       "        3.48165099e-06, 4.68159851e-06],\n",
       "       [3.17886517e-08, 1.26459741e-03, 9.98728454e-01, 1.60590400e-06,\n",
       "        5.67803115e-15, 5.23637664e-06, 1.26770544e-07, 7.78675995e-12,\n",
       "        2.42450948e-08, 2.47496929e-13],\n",
       "       [5.80423546e-07, 9.99342859e-01, 2.43364368e-04, 7.71040413e-06,\n",
       "        3.90747082e-05, 6.07469656e-06, 9.29760517e-06, 3.05542344e-04,\n",
       "        4.50287880e-05, 4.28050129e-07],\n",
       "       [9.99188483e-01, 9.14287046e-09, 2.40307141e-04, 9.36814558e-07,\n",
       "        3.77344418e-06, 3.99901410e-06, 1.72026539e-05, 4.73355991e-04,\n",
       "        2.10491493e-07, 7.15603892e-05],\n",
       "       [1.16343006e-06, 6.12263946e-08, 9.89188175e-06, 5.51805606e-08,\n",
       "        9.98419046e-01, 6.58728027e-07, 8.84277233e-06, 4.30492219e-05,\n",
       "        4.70072109e-06, 1.51254749e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}